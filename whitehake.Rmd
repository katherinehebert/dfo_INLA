---
title: "Spatiotemporal modelling of White Hake populations in the Southern Gulf of the St-Lawrence"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(INLA)
library(raster)
library(patchwork)
library(sf)
library(tidyverse)
# library(inlatools) # remotes::install_github("inbo/inlatools")
# devtools::install_github("gfalbery/ggregplot")
library(ggregplot)
#library(animation)
```

## Prepare the data

This data is STDIF structure - a class for unstructured spatio-temporal data, with n spatial locations and times, where n observations are available, from the `spacetime` package.

The 0s actually reflect that there were no observations at that time - in other words, they are _not_ false absences, and should not be removed.

```{r load data, echo = FALSE}
explan <- readRDS("data/explan.RDS")
number <- readRDS("data/number.RDS")
gulf <- readRDS("data/gulf.RDS")

# STDIF = space, time, data frame, i = irregular grid
head(number@sp)
head(number@time) # it has a time zone structure!!
head(number@endTime)

# subset to species of focus
#whitehake <- number
#whitehake@data <- subset(whitehake@data, select = "WHITE HAKE")
```

## Data exploration

### White hake abundances 

#### Through time

```{r plot-abundances}
plot(number@endTime, number@data$`WHITE HAKE`, type = "l")
```

#### In space

```{r map-abundances}
plot(number@sp, pch = 19, cex = number@data$`WHITE HAKE`/300)
plot(gulf, add = TRUE)
```

### Explanatory variables

```{r map-explan}
# function to add coordinates to dataset in preparation for conversion to sf
add_coords <- function(stidf_object){
  # assign datasets to objects to simplify the code a bit
  df <- stidf_object@data 
  coords <- stidf_object@sp@coords

  # add coordinate columns to dataset
  df <- mutate(df,
           longitude = coords[,1],
           latitude = coords[,2],
           time = lubridate::date(stidf_object@endTime),
           year = lubridate::year(stidf_object@endTime)
           )
  return(df)
}

# convert datasets to sf objects

explan_sf <- add_coords(explan) %>%
  st_as_sf(x = ., coords = c("longitude", "latitude"))
st_crs(explan_sf) <- explan@sp@proj4string # set coordinate ref system

gulf_sf <- st_as_sf(gulf)
st_crs(gulf_sf) <- gulf@proj4string # set coordinate ref system

# maps

# ggplot map of explanatory variable
p1 <- ggplot() +
  geom_sf(data = gulf_sf, fill = "white") +
  geom_sf(data = filter(explan_sf, 
                        # pick a sequence of years to check out
                        year %in% c(1971, 1981, 1992, 2001, 2011, 2019)),
          aes(col = bottom.temperature)) +
  facet_wrap(~year) +
  scale_color_viridis_c(option = "viridis") +
  labs(color = "Bottom \ntemperature") +
  theme_void() 

p2 <- ggplot() +
  geom_sf(data = gulf_sf, fill = "white") +
  geom_sf(data = filter(explan_sf, 
                        # pick a sequence of years to check out
                        year %in% c(1971, 1981, 1992, 2001, 2011, 2019)),
          aes(col = bottom.salinity)) +
  facet_wrap(~year) +
  scale_color_viridis_c(option = "viridis") +
  labs(color = "Bottom \nsalinity") +
  theme_void()

p3 <- ggplot() +
  geom_sf(data = gulf_sf) +
  geom_sf(data = filter(explan_sf, 
                        # pick a sequence of years to check out
                        year %in% c(1971, 1981, 1992, 2001, 2011, 2019)),
          aes(col = depth)) +
  facet_wrap(~year) +
  scale_color_viridis_c(option = "viridis") +
  labs(color = "Depth") +
  theme_void() 

# patchwork together!
p1 / p2 / p3
```



## Step 1 - Building the meshes

This mesh size reflects the range of coordinates in space. Changing to a smaller value, like 35000, gives a more appropriate mesh.

```{r spatial-mesh}
maxEdge <- 35000
meshSpace <- inla.mesh.2d(boundary = gulf,
                          max.edge = maxEdge*c(0.5,2),
                          offset = c(10000,20000),
                          cutoff = maxEdge/2)

# plot points under the mesh, to see if it makes sense
par(mar = c(1,1,1,1))
plot(number@sp, pch = 19, cex = 0.2, col = "red")
plot(gulf, add = TRUE)
plot(meshSpace, main = "", asp = 1, add = TRUE)

# plot abundances under the mesh too
plot(number@sp, pch = 19, cex = number@data$`WHITE HAKE`/300, col = "red")
plot(gulf, add = TRUE)
plot(meshSpace, main = "", asp = 1, add = TRUE)
```
```{r edge-number}
# Number of edges in the mesh
meshSpace$n
```


```{r time-mesh}
### Time
time <- as.numeric(number@endTime)/60 # Number of minutes since Jan 1, 1970 

timeBasis <- time - 884844 # Time starting at 1

# Division points
# timeGr <- 11
# timeSeq <- seq(min(timeBasis),
#                max(timeBasis),
#                length = timeGr)
# meshTime <- inla.mesh.1d(timeSeq)
# ^ This divides time into 11 bins of minutes since 1970.
timeGr <- 2

# try with two extreme time points, just to simplify the model run
meshTime <- inla.mesh.1d(c(min(timeBasis), max(timeBasis)))
```

How many estimations will be carried out?
```{r complexity-mesh}
meshSpace$n * meshTime$n
```

## Step 2 - Define the stochastic partial differential equation

```{r spde, echo = FALSE}
SPDE <- inla.spde2.pcmatern(mesh=meshSpace, # where we want to estimate
                            alpha=2, # must be between 0 and 2. this makes it curved rather than too sharp
                            prior.range=c(1000, 0.5), # distance at which the prior levels off;
                            # at a range of 100m, things should level off
                            # 0.5 means this is 50% likely. this gives a weight to the priors.
                            prior.sigma=c(35, 0.5) # amount of variance where it plateaus (slide 36/41)
                            )
# basis to build spatial structure of the model

# To set prior.sigma
sd(number@data$`WHITE HAKE`)
```

## Step 3 - Priors and hyperparameters for temporal autocorrelation

```{r priors}
# Temporal autocorrelation prior
hSpec <- list(theta=list(prior='pccor1', param=c(0.2, 0.9))) 
# assuming not a lot of temporal autocorrelation (0.2) and we are fairly sure of that (0.9)

# Precision likelihood 
## (negative binomial or any distribution that has more than one parameter)
# precPrior <- list(prior='pc.prec', param=c(1, 0.01))
# guessing it's 1 with a confidence of .01, which is super low.

# note ^ is not useful if using a Poisson.
```


## Step 4 - Index matrix

```{r index-matrix}
Field <- inla.spde.make.index("field", 
                              n.spde = SPDE$n.spde,
                              n.group = meshTime$n)
```


## Step 5 - A matrix

```{r a-matrix}
# For estimation
A <- inla.spde.make.A(meshSpace,
                      loc = coordinates(number@sp),
                      group = timeBasis,
                      group.mesh = meshTime)
```

## Step 6 - Organise the A matrix into a list

```{r a-matrix-list}
Alist <- as.list(rep(1,4)) # list with single values
Alist[[1]] <- A
```


## Step 7 - Organise the effects (spatial autocorrelation structure and explanatory variables)

Here, we're using two variables about the bottom conditions, because White hake is a groundfish.
```{r org-effects}
effect <- list(Field,
               bTemp =  explan@data$bottom.temperature,
               bSal = explan@data$bottom.salinity,
               bDep = explan@data$depth)
```


## Step 8 - Build stack

```{r build-stack}
Stack <- inla.stack(data=list(whitehake = number@data$`WHITE HAKE`),
                    A = Alist,
                    effects = effect,
                    tag="basis")
```

## Step 9 - Building the model (Finally!)

```{r build-model}
# to find the distributions that are available
# inla.models()$likelihood$poisson

form <- whitehake ~ 0 + bTemp + bSal + bDep +
        f(field, # temporal autocorr
          model=SPDE, # spatial autocorr structure
          group = field.group, # how they're grouped
          control.group=list(model='ar1', hyper=hSpec) # build with model parameters
          )

model_gaussian <- inla(form,
              data = inla.stack.data(Stack),
              family="gaussian",
              control.family = list(link="identity"),
              control.predictor = list(A = inla.stack.A(Stack), 
                                       compute = TRUE, 
                                       link = 1),
              control.compute = list(waic = TRUE,
                                     config = TRUE))
#saveRDS(model_gaussian, "outputs/whitehake_model.RDS")
```

## Checking and interpreting the model

```{r output-model}
summary(model_gaussian)
```

```{r check-model}
Efxplot(list(model_gaussian)) + theme_classic()
# from Coding Club tutorial: "NB: There are no P values in INLA. Importance or significance of variables can be deduced by examining the overlap of their 2.5% and 97.5% posterior estimates with zero."
```

```{r check-residuals-Zuurbook}
ExpY <- model_gaussian$summary.fitted.values[1:nrow(number@data),"mean"]

#For the variance we also need the posterior mean value of Î¸, which is obtained via
phi1 <- model_gaussian$summary.hyper[1, "mean"]

#The variance is then given by
VarY <- ExpY * (1 - ExpY) / (1 + phi1)

# And once we have the mean and the variance we can calculate Pearson residuals.
E1 <- (number@data$`WHITE HAKE` - ExpY) / sqrt(VarY)

# Apply model validation
# Figure 23.11
par(mfrow = c(1,1), mar = c(5,5,2,2), cex.lab = 1.5)
plot(x = model_gaussian$summary.fitted.values$mean[1:nrow(number@data)], 
     y = E1,
     xlab = "Fitted values",
     ylab = "Pearson residuals",
     xlim = c(0,1))
abline(h = 0, lty = 2)
# note: there's a value at 130...
```


#### Fixed effects

This is the output you would get from a normal linear model.
- mode: mode of the parameters distribution
- kld: ????

#### Random effects

Field group is the random effect we set earlier.

#### DF

Distribution for the parameter picked with mean, sd, and credible interval

#### Predictions through space and time

```{r predict-model}
# Dimension of the raster
stepsize <- 1000 # choose cell size: 1000m x 1000m
rangeX <- range(meshSpace$loc[,1])
rangeY <- range(meshSpace$loc[,2])
nxy <- round(c(diff(rangeX), 
               diff(rangeY)) / stepsize)

# Define basis of the map
mapBasis <- inla.mesh.projector(meshSpace,
                               xlim = rangeX,
                               ylim = rangeY,
                               crs = crs(gulf))


# Calculate prediction
mapMean <- vector("list", length = timeGr)
map.025 <- vector("list", length = timeGr)
map.975 <- vector("list", length = timeGr)

# for every time point
for(i in 1:timeGr){
  # Model prediction
  fitMean <- inla.mesh.project(mapBasis, 
                          model_gaussian$summary.random$field$mean[1:SPDE$n.spde + (i - 1) * SPDE$n.spde])
  fit.025 <- inla.mesh.project(mapBasis, 
                               model_gaussian$summary.random$field$`0.025quant`[1:SPDE$n.spde + (i - 1) * SPDE$n.spde])
  fit.975 <- inla.mesh.project(mapBasis, 
                               model_gaussian$summary.random$field$`0.975quant`[1:SPDE$n.spde + (i - 1) * SPDE$n.spde])

  # Build maps with confidence intervals
  mapMean[[i]] <- raster(t(fitMean[,ncol(fitMean):1]),
                         xmn = min(mapBasis$x), xmx = max(mapBasis$x), 
                         ymn = min(mapBasis$y), ymx = max(mapBasis$y),
                         crs = crs(gulf))

  map.025[[i]] <- raster(t(fit.025[,ncol(fit.025):1]),
                         xmn = min(mapBasis$x), xmx = max(mapBasis$x), 
                         ymn = min(mapBasis$y), ymx = max(mapBasis$y),
                         crs = crs(gulf))
  
  map.975[[i]] <- raster(t(fit.975[,ncol(fit.975):1]),
                         xmn = min(mapBasis$x), xmx = max(mapBasis$x), 
                         ymn = min(mapBasis$y), ymx = max(mapBasis$y),
                         crs = crs(gulf))
}  

# Convert to a rasterStack (aligns the elements of a list)
rasterMean <- stack(mapMean)
raster.025 <- stack(map.025)
raster.975 <- stack(map.975)
  # to check this visually: 
  # image(mapMean[[1]])
  # plot(meshSpace, add = TRUE)

# reorganise
# for(i in 1:5){
#   values(rasterMean)[,i] <- as.vector(t(mapMean[[i]]))
#   values(raster.025)[,i] <- as.vector(t(map.025[[i]]))
#   values(raster.975)[,i] <- as.vector(t(map.975[[i]]))
# }

# Mask the region to keep only the region of interest
rasterMeanMask <- mask(rasterMean, gulf)
raster.025Mask <- mask(raster.025, gulf)
raster.975Mask <- mask(raster.975, gulf)
image(rasterMeanMask)
plot(gulf, add = TRUE)

```

```{r map-predictions}
# Map the results
par(mfrow = c(2,3), mar = c(1,1,3,1))

for(i in 1:timeGr){
zlimRange <- range(values(raster.025Mask[[i]]),
                   values(rasterMeanMask[[i]]),
                   values(raster.975Mask[[i]]), na.rm = TRUE)
}

# convert to data frames for ggplot
raster.025Mask_df <- as.data.frame(raster.025Mask, xy = TRUE, na.rm = TRUE)
rasterMeanMask_df <- as.data.frame(rasterMeanMask, xy = TRUE, na.rm = TRUE)
raster.975Mask_df <- as.data.frame(raster.975Mask, xy = TRUE, na.rm = TRUE)


# function to plot model results using ggplot2
result_map <- function(raster_df, column_name, title){
  p <- ggplot() +
    geom_raster(data = raster_df, 
                aes(x = x, y = y, fill = get(column_name))) + 
    labs(fill = "Abundance") +
    scale_fill_distiller(palette = "RdBu", 
                         limits = c(-max(abs(raster.975Mask_df[,column_name])), 
                                    max(abs(raster.975Mask_df[,column_name])))) +
    theme_void()  
  return(p)
}

# 2.5% credible limit
p1.025 <- result_map(raster.025Mask_df, "layer.1") + theme(legend.position = "none")
p2.025 <- result_map(raster.025Mask_df, "layer.2") + theme(legend.position = "none")

# mean
p1.mean <- result_map(rasterMeanMask_df, "layer.1") + theme(legend.position = "none")
p2.mean <- result_map(rasterMeanMask_df, "layer.2") + theme(legend.position = "none")

# 97.5% credible limit
p1.975 <- result_map(raster.975Mask_df, "layer.1") + theme(legend.position = "bottom")
p2.975 <- result_map(raster.975Mask_df, "layer.2") + theme(legend.position = "bottom")

# patchwork together
(p1.025 + p2.025) / (p1.mean + p2.mean) / (p1.975 + p2.975)
```

Compare the models with wAIC

Attempt with gamma distribution

```{r}

# try to see residuals of the model_gaussian
hist(number@data$`WHITE HAKE`) 

precGamma <- list(prior = "pc.gamma", param = c(1, .1))

# not running because y has zeros?
model_gamma <- inla(form,
              data = inla.stack.data(Stack),
              family="gamma",
              control.family = list(link = "log",
                hyper = list(theta = list(precGamma$prior))),
              control.predictor = list(A = inla.stack.A(Stack), 
                                       compute = TRUE, 
                                       link = 1),
              control.compute = list(waic = TRUE,
                                     config = TRUE))
```

